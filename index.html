<!DOCTYPE html>
<!-- saved from url=(0055)https://www.starlg.cn/TianliangZhang/TianliangZhang.htm -->
<html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <meta content="IE=5.0000" http-equiv="X-UA-Compatible">
  <meta name="description" content="Yiwei Ma&#39;s home page">
  
  <link href="./imgs/tlzdoc.css" rel="stylesheet" type="text/css">
  <title>Yiwei Ma's Homepage--马祎炜的个人主页</title>
  <meta name="GENERATOR" content="MSHTML 11.00.10570.1001">
</head>


<body>
  <div id="layout-content" style="margin-top: 25px;">
  <table>
    <tbody>
    <tr>
      <td>
        <img width="130" src="./imgs/YWM2.jpg" border="3">
      </td>	
      <td width="670">
        <div id="toptitle">
        <h1>Yiwei Ma &nbsp; 马祎炜<a name="top"></a></h1>
		</div>
        <h3>First-year Ph. D Student at Xiamen University        </h3>
        <p> 
        <br> Email:
        <a href="yiweima@stu.xmu.edu.cn">yiweima@stu.xmu.edu.cn</a>		
        <br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
	&nbsp;&nbsp;<a href="https://github.com/xmu-xiaoma666" target="_blank">[Github]</a>
	&nbsp;&nbsp;<a href="https://scholar.google.com.tw/citations?view_op=list_works&hl=zh-CN&user=KIDY5pUAAAAJ&gmla=AJsN-F4drnWeD3U5c9Th0ilgoeYuA0ovsr6N0yHUPVd_p2nM8vLRZVhrULm2rX70XnaGQ87xDo_CVYZKyWNmA3-TorzrKBZY84fX0tg-Q3v68HIvYA3y-GY_fzt515GksJC0TgSvPyxK" target="_blank">[Google Scholar]</a>	
  <!--      &nbsp;&nbsp;<a href="#" target="_blank">[Ph.D. Thesis, in Chinese]</a>		-->
        <br><br></p>
      </td>
    </tr>
    <tr></tr></tbody>
  </table>
  <div id="layout-content" style="margin-top: 25px;">


<h4>[<a style=" color:#9D849A;" href="#biography">Biography</a>] [<a style=" color:#9D849A;" href="#news">Latest News</a>] 
  [<a style=" color:#9D849A;" href="#publications">Publications</a>] 
[<a style=" color:#9D849A;" href="#projects">Projects</a>] 
[<a style=" color:#9D849A;" href="#awards">Major Awards</a>] 
[<a style=" color:#9D849A;" href="#patent">Patent</a>] 
[<a style=" color:#9D849A;" href="#activities">Professional Activities</a>]</h4>

<h2>Biography<a name="biography"></a>&nbsp;&nbsp;&nbsp;<a style=" color:#9D849A; font-size:15px;" href="#top">[back top]</a></h2>
  <p style="text-indent:2em;"> I am currently a first-year Ph.D student in <a href="https://cogsci.xmu.edu.cn/" target="_blank">Department of Artificial Intelligence</a>, <a href="https://informatics.xmu.edu.cn/" target="_blank">School of Informatics</a>, <a href="https://en.xmu.edu.cn/" target="_blank">Xiamen University</a>, advised by <a href="https://mac.xmu.edu.cn/rrji_en/" target="_blank">Prof. Rongrong Ji</a> and <a href="https://sites.google.com/view/xssun" target="_blank">Prof. Xiaoshuai Sun</a> .
  </p>
  <p style="text-indent:2em;">My recent research interests are in (2D/3D) vision-and-language learning.</p>

<ul>  
  <li> 09/2023 -- Now: Ph.D. in Intelligence Science and Technology, <a href="https://en.xmu.edu.cn/" target="_blank">Xiamen University</a>, Xiamen, China</li>   
  <li> 09/2020 -- 06/2023: M.S. in Intelligence Science and Technology, <a href="https://en.xmu.edu.cn/" target="_blank">Xiamen University</a>, Xiamen, China</li>   
  <li> 12/2021 -- 05/2022: Research Intern, <a href="https://damo.alibaba.com/labs/?goto=1" target="_blank">Alibaba DAMO Academy</a>, Hangzhou, China </li>
  <!-- <li> 09/2018 -- 06/2021: M.S. in Computer Technology, <a href="https://en.xmu.edu.cn/" target="_blank">Xiamen University</a>, Xiamen, China </li>   -->
  <li> 09/2016 -- 06/2020: B.S. in Digital Media Technology, <a href="https://english.zstu.edu.cn/" target="_blank">Zhejiang Sci-Tech University</a>, Hangzhou, China </li>
</ul>


<h2>Latest News<a name="news"></a>&nbsp;&nbsp;&nbsp;<a style=" color:#9D849A; font-size:15px;" href="#top">[back top]</a></h2>
<ul>  
  <li> 07/2023: Three paper accepted by <i>ACM MM</i></li>
  <li> 07/2023: One paper accepted by <i>ICCV</i></li>
  <li> 02/2023: One paper accepted by <i>Pattern Recognition (PR)</i></li>
  <!-- <li> 02/2023: One paper accepted by IEEE Access</li> -->
  <!-- <li> 06/2022: One paper accepted by ACM MM</li>
  <li> 05/2022: One paper accepted by IEEE TIP</li>
  <li> 04/2022: One paper accepted by IEEE TMM</li>   -->
</ul>


<h2>Publications<a name="publications"></a>&nbsp;&nbsp;&nbsp;<a style=" color:#9D849A; font-size:15px;" href="#top">[back top]</a></h2>
<h3>Journal</h3>
<table class="pub_table">
  <tbody>

    <tr>
      <td class="pub_td1"> <img src="./imgs/LSTNet.png" class="papericon"></td>
      <td class="pub_td2">  <font color="goldenrod">Yiwei Ma</font>, Jiayi Ji, Xiaoshuai Sun<sup>✉</sup>, Yiyi Zhou, Rongrong Ji
        <br><b>Towards Local Visual Modeling for Image Captioning</b>
        <br>Pattern Recognition (PR), 2023<br>
        [<a href="https://www.sciencedirect.com/science/article/abs/pii/S0031320323001218" target="_blank">PDF</a>]	
        [<a href="https://arxiv.org/abs/2302.06098" target="_blank">ArXiv</a>]	
        [<a href="https://github.com/xmu-xiaoma666/LSTNet" target="_blank">Code</a>]	
      </td>
    </tr>   	 
   
    <tr>
      <td class="pub_td1"> <img src="./imgs/RAS-FSG.png" class="papericon"></td>
      <td class="pub_td2"> Yinan Li, <font color="goldenrod">Yiwei Ma</font>, Yiyi Zhou,  Xiao Yu<sup>✉</sup>,
        <br><b>Semantic-Guided Selective Representation for Image Captioning</b>
        <br>IEEE Access, 2023<br>
        [<a href="https://ieeexplore.ieee.org/document/10041895" target="_blank">PDF</a>]	
      </td>
    </tr>   	 

  <tr>
    <td class="pub_td1"> <img src="./imgs/EMFM.png" class="papericon"></td>
    <td class="pub_td2"> Jiayi Ji, <font color="goldenrod">Yiwei Ma (co-frist author)</font>, Xiaoshuai Sun<sup>✉</sup>, Yiyi Zhou, Yongjian Wu, Rongrong Ji
      <br><b>Knowing What to Learn: A Metric-oriented Focal Mechanism for Image Captioning</b>
      <br>IEEE Transactions on Image Processing (TIP), 2022<br>
      [<a href="https://ieeexplore.ieee.org/document/9802801" target="_blank">PDF</a>]	
      [<a href="https://github.com/xmu-xiaoma666/MFM" target="_blank">Code</a>]	
    </td>
  </tr>   	 


  <tr>
    <td class="pub_td1"> <img src="./imgs/SDATR.png" class="papericon"></td>
    <td class="pub_td2"> <font color="goldenrod">Yiwei Ma</font>, Jiayi Ji, Xiaoshuai Sun<sup>✉</sup>, Yiyi Zhou, Yongjian Wu, Feiyue Huang, Rongrong Ji
      <br><b>Knowing what it is: Semantic-enhanced Dual Attention Transformer</b>
      <br>IEEE Transactions on Multimedia (TMM), 2022<br>
      [<a href="https://ieeexplore.ieee.org/document/9749944" target="_blank">PDF</a>]	 
      [<a href="https://github.com/xmu-xiaoma666/SDATR" target="_blank">Code</a>]                    
    </td>
  </tr>   	 


  </tbody>
</table>


<h3>Conference</h3>
<table class="pub_table">
  <tbody>


    <tr>
      <td class="pub_td1"> <img src="./imgs/BEAT.png" class="papericon"></td>
      <td class="pub_td2"><font color="goldenrod">Yiwei Ma</font>, Jiayi Ji, Xiaoshuai Sun<sup>✉</sup>, Guannan Jiang, Weilin Zhuang, Rongrong Ji
        <br><b>Beat: Bi-directional One-to-Many Embedding Alignment for Text-based Person Retrieval</b>
        <br>ACM International Conference on Multimedia (ACM MM), 2023<br>
      [<a href="#" target="_blank">PDF Comming</a>] 
      [<a href="https://github.com/xmu-xiaoma666/Beat" target="_blank">Code</a>]  
      [<a href="https://xmu-xiaoma666.github.io/Projects/MM23_BEAT/" target="_blank">Project Page</a>]
      </td>
    </tr>  


    <tr>
      <td class="pub_td1"> <img src="./imgs/JM3D.png" class="papericon"></td>
      <td class="pub_td2">Haowei Wang, Jiji Tang, Jiayi Ji, Xiaoshuai Sun<sup>✉</sup>, Rongsheng Zhang, <font color="goldenrod">Yiwei Ma</font>, Minda Zhao, Lincheng Li, Zeng Zhao, Tangjie Lv, Rongrong Ji
        <br><b>Beyond First Impressions: Integrating Joint Multi-modal Cues for Comprehensive 3D Representation</b>
        <br>ACM International Conference on Multimedia (ACM MM), 2023<br>
      [<a href="#" target="_blank">PDF Comming</a>] 
      [<a href="https://arxiv.org/abs/2308.02982" target="_blank">arXiv</a>] 
      [<a href="https://github.com/Mr-Neko/JM3D" target="_blank">Code</a>]  
      </td>
    </tr>  


    <tr>
      <td class="pub_td1"> <img src="./imgs/SSPNG.png" class="papericon"></td>
      <td class="pub_td2">Danni Yang, Jiayi Ji, Xiaoshuai Sun<sup>✉</sup>, Haowei Wang, Yinan Li, <font color="goldenrod">Yiwei Ma</font>, Rongrong Ji
        <br><b>Semi-Supervised Panoptic Narrative Grounding</b>
        <br>ACM International Conference on Multimedia (ACM MM), 2023<br>
      [<a href="#" target="_blank">PDF Comming</a>] 
      [<a href=" https://github.com/nini0919/SSPNG" target="_blank">Code</a>]  
      </td>
    </tr>  


    <tr>
      <td class="pub_td1"> <img src="./imgs/XMesh.png" class="papericon"></td>
      <td class="pub_td2"><font color="goldenrod">Yiwei Ma</font>, Xiaoqing Zhang, Xiaoshuai Sun<sup>✉</sup>, Jiayi Ji, Haowei Wang, Guannan Jiang, Weilin Zhuang, Rongrong Ji
        <br><b>X-Mesh:Towards Fast and Accurate Text-driven 3D Stylization via Dynamic Textual Guidance</b>
        <br>IEEE International Conference on Computer Vision (ICCV), 2023<br>
      [<a href="https://arxiv.org/abs/2303.15764" target="_blank">arXiv</a>] 
      [<a href="https://github.com/xmu-xiaoma666/X-Mesh" target="_blank">Code</a>]  
      [<a href="https://xmu-xiaoma666.github.io/Projects/X-Mesh/" target="_blank">Project Page</a>]
      </td>
    </tr>    


  <tr>
    <td class="pub_td1"> <img src="./imgs/XCLIP.png" class="papericon"></td>
    <td class="pub_td2"> <font color="goldenrod">Yiwei Ma</font>, Guohai Xu, Xiaoshuai Sun<sup>✉</sup>, Ming Yan, Ji Zhang, Rongrong Ji
      <br><b>X-CLIP: End-to-End Multi-grained Contrastive Learning for Video-Text Retrieval</b>
      <br>ACM International Conference on Multimedia (ACM MM), 2022<br>
      [<a href="https://dl.acm.org/doi/abs/10.1145/3503161.3547910" target="_blank">PDF</a>]	 
       [<a href="https://arxiv.org/abs/2207.07285" target="_blank">arXiv</a>]
      [<a href="https://github.com/xuguohai/X-CLIP" target="_blank">Code</a>]  
      [<a href="https://xmu-xiaoma666.github.io/Projects/MM22_XCLIP/" target="_blank">Project Page</a>]
    </td>
  </tr>





  </tbody>
</table>

<h3>Preprint</h3>
<table class="pub_table">
  <tbody>
	  <!-- Waiting ... -->
	
  <tr>
    <td class="pub_td1"> <img src="./imgs/3D-STMN.png" class="papericon"></td>
    <td class="pub_td2">Changli Wu, <font color="goldenrod">Yiwei Ma</font>, Qi Chen, Haowei Wang, Gen Luo, Jiayi Ji<sup>✉</sup>, Xiaoshuai Sun
      <br><b>3D-STMN: Dependency-Driven Superpoint-Text Matching Network for End-to-End 3D Referring Expression Segmentation</b>
      <br>arXiv preprint 	arXiv:2308.16632 , 2023
      <br>
	  [<a href="https://arxiv.org/abs/2303.15764" target="_blank">arXiv</a>] 
    [<a href="https://github.com/sosppxo/3D-STMN" target="_blank">Code</a>]  
    <!-- [<a href="https://xmu-xiaoma666.github.io/Projects/X-Mesh/" target="_blank">Project Page</a>] -->

    </td>
  </tr>    


  </tbody>
</table>



<h2>Projects<a name="projects"></a>&nbsp;&nbsp;&nbsp;<a style=" color:#9D849A; font-size:15px;" href="#top">[back top]</a></h2>
<h3></h3>
<table class="pub_table">

  <tr>
    <td class="pub_td1"> <img src="./imgs/attention_git.png" class="papericon"></td>
    <td class="pub_td2"> 
      <br><b>External-Attention-pytorch</b>
      <br>Pytorch implementation of various Attention Mechanisms, MLP, Re-parameter, Convolution, which is helpful to further understand papers.<br>
      [<a href="https://github.com/xmu-xiaoma666/External-Attention-pytorch" target="_blank">github </a>] <font color="#FF0000"><i>(9300+ stars)</i></font>  
    </td>
  </tr>


</table>



<h2>Patent<a name="patent"></a>&nbsp;&nbsp;&nbsp;<a style=" color:#9D849A; font-size:15px;" href="#top">[back top]</a></h2>
<h3></h3>
<table class="pub_table">

  <tr>
    <td class="pub_td1"> <img src="./patent/XCLIP.jpg" class="papericon"></td>
    <td class="pub_td2"> 
      <br><b>面向视频文本检索的端到端多粒度对比学习方法</b>
      <br>CN115757713A<br>
      [<a href="https://www.baiten.cn/patent/detail/84129a8ff543f9fa1697375de7b1af074ca8c13bb7a43aaf?sc=&fq=&type=&sort=&sortField=&q=%E9%A9%AC%E7%A5%8E%E7%82%9C%2B%E5%8E%A6%E9%97%A8%E5%A4%A7%E5%AD%A6&rows=10#1/CN202211310816.5/detail/abst" target="_blank">详情</a>] 
    </td>
  </tr>

  
  <tr>
    <td class="pub_td1"> <img src="./patent/caption1.jpg" class="papericon"></td>
    <td class="pub_td2"> 
      <br><b>面向局部视觉建模的图像描述生成方法</b>
      <br>CN115964530A<br>
      [<a href="https://www.baiten.cn/patent/detail/bb65a03c36e01639e02e6614b74adfc8271986998898c0b2?sc=&fq=&type=&sort=&sortField=&q=%E9%A9%AC%E7%A5%8E%E7%82%9C%2B%E5%8E%A6%E9%97%A8%E5%A4%A7%E5%AD%A6&rows=10#1/CN202310040601.4/detail/abst" target="_blank">详情</a>] 
    </td>
  </tr>


  
  <tr>
    <td class="pub_td1"> <img src="./patent/BEAT.jpg" class="papericon"></td>
    <td class="pub_td2"> 
      <br><b>基于文本的人物检索的双向一对多嵌入对齐方法</b>
      <br>CN116304145A<br>
      [<a href="https://www.baiten.cn/patent/detail/84129a8ff543f9fa1697375de7b1af074ca8c13bb7a43aaf?sc=&fq=&type=&sort=&sortField=&q=%E9%A9%AC%E7%A5%8E%E7%82%9C%2B%E5%8E%A6%E9%97%A8%E5%A4%A7%E5%AD%A6&rows=10#1/CN202310298214.0/detail/abst" target="_blank">详情</a>] 
    </td>
  </tr>

</table>



<h2>Major Awards<a name="awards"></a>&nbsp;&nbsp;&nbsp;<a style=" color:#9D849A; font-size:15px;" href="#top">[back top]</a></h2>
<ul>
  
    <li>  National Scholarship, China, 2022  </li> 
    <li>  Excellent Graduate of of ZheJiang Province, China, 2020  </li> 
    <li>  National Scholarship, China, 2019  </li> 
    <li>  Zhejiang Provincial Government Scholarship, 2018  </li>
</ul>

<h2>Professional Activities<a name="activities"></a>&nbsp;&nbsp;&nbsp;<a style=" color:#9D849A; font-size:15px;" href="#top">[back top]</a></h2>
<ul>
  <li> Conference Reviewer: ACMMM 2023, ICCV 2023</li>
  <!-- <li> Journal Reviewer: IEEE Transactions on Circuits and Systems for Video Technology </li> -->
</ul>


</div>
</div>
</body>
</html>
